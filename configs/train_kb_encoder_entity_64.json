{
    "configs": [
        {
            "accumulate_grad_batches": 4,
            "base_configs": {},
            "base_type": "bert-large-uncased",
            "batch_size": 8,
            "context_length": 32,
            "dataset": "KDWD",
            "dataset_config": {
                "force_reload": false,
                "graph_depth": 1,
                "permute_seed": 0,
                "train_entity_encode_ratio": 0.9,
                "train_relation_encode_ratio": 0.9,
                "relation_mask_mode": "part"
            },
            "epochs": 100,
            "l2_regularization": 0,
            "learning_rate": 5e-05,
            "load": true,
            "max_seq_length": 64,
            "mlp_hidden_size": [],
            "optimizer_class": "Adam",
            "relation_mode": "subtraction",
            "relation_size": 200,
            "seed": 0,
            "task": "entity",
            "train_steps": null,
            "validate_steps": null
        }
    ],
    "early_stopping_patience": 100,
    "gpus": [
        0, 1, 2, 3, 4, 5, 6, 7
    ],
    "pipeline": [
        "kb_encoder"
    ],
    "working_directory": "/data/workspace/kb-ae-bert/train_entity_64"
}