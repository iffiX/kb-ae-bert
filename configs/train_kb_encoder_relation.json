{
    "configs": [
        {
            "accumulate_grad_batches": 32,
            "base_configs": {},
            "base_type": "bert-large-uncased",
            "batch_size": 2,
            "context_length": 32,
            "dataset": "KDWD",
            "dataset_config": {
                "force_reload": false,
                "graph_depth": 1,
                "permute_seed": 0,
                "train_entity_encode_ratio": 0.9,
                "train_relation_encode_ratio": 0.9,
                "relation_mask_mode": "part"
            },
            "epochs": 200,
            "l2_regularization": 0,
            "learning_rate": 5e-05,
            "load": true,
            "max_seq_length": 64,
            "mlp_hidden_size": [],
            "optimizer_class": "Adam",
            "relation_mode": "subtraction",
            "relation_size": 200,
            "seed": 0,
            "task": "relation",
            "train_steps": 5000,
            "validate_steps": 100
        }
    ],
    "early_stopping_patience": 100,
    "gpus": [
        0, 1, 2, 3
    ],
    "pipeline": [
        "kb_encoder"
    ],
    "working_directory": "/root/data/workspace/kb-ae-bert/train-relation"
}